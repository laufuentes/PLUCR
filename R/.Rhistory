beta <- 0.05
lambda <- 0
mu0 <- mu.hat.nj[[fold]]
nu0 <- nu.hat.nj[[fold]]
prop_score <- ps.hat.nj[[fold]]
out <- PLUCR::Optimization_Estimation(mu0, nu0, prop_score,
X, Treatment, Y, Xi,
lambda, alpha, precision, beta, centered,
paste0(lambda,"_",beta,"_",fold), paste0(lambda,"_",beta,"_",fold))
devtools::document("./Documents/PhD/Project 1 - Policy learning - Constraints - Multiple outcome/PLUCR_package/PLUCR/")
devtools::load_all("./Documents/PhD/Project 1 - Policy learning - Constraints - Multiple outcome/PLUCR_package/PLUCR/")
rm(list=objects())
graphics.off()
`%>%`<- magrittr::`%>%`
library(PLUCR)
########################################
#  Preliminary step: Data preparation  #
########################################
## Parameters
n <- 2*1e3 # number of individuals
JFold <- 5 # Number of folds
Lambdas <- seq(0,8,by=1) # Lambda candidates
Betas <- c(0.05, 0.5, 1, 2) # Beta candidates
alpha <- 0.1 # constraint tolerance
precision <- 0.025 # Frank-Wolfe desired precision
centered <- FALSE
## Data generation
exp <- PLUCR::data_gen(n,seed=2025)
# Complete data
df_complete <- exp[[1]]
# Observational data
df_obs <- exp[[2]]
X <- df_obs %>%
dplyr::select(starts_with("X."))%>%
as.matrix()
Treatment <- df_obs$Treatment
Y <- df_obs$Y
Xi <- df_obs$Xi
# Folds for cross-validation
folds <- SuperLearner::CVFolds(N = n,id = NULL,Y = X,
cvControl = list(V = JFold, stratifyCV = FALSE, shuffle = TRUE))
folds_df <- do.call(rbind, lapply(seq_along(folds), function(v){data.frame(index=folds[[v]], fold=v)}))
s <- folds_df$fold[order(folds_df$index)]
########################################
# Step 1: Compute nuissance parameters #
########################################
initial_nparams <- PLUCR::nuissance_params(X, Treatment, Y, Xi,s)
# Primary outcome model
mu.hat.nj <- initial_nparams[[2]]
# Adverse event model
nu.hat.nj <- initial_nparams[[3]]
# Propensity score
ps.hat.nj <- initial_nparams[[4]]
fold <- 1
beta <- 0.05
lambda <- 0
mu0 <- mu.hat.nj[[fold]]
nu0 <- nu.hat.nj[[fold]]
prop_score <- ps.hat.nj[[fold]]
out <- PLUCR::Optimization_Estimation(mu0, nu0, prop_score,
X, Treatment, Y, Xi,
lambda, alpha, precision, beta, centered,
paste0(lambda,"_",beta,"_",fold), paste0(lambda,"_",beta,"_",fold))
library(tibble)
devtools::document("./Documents/PhD/Project 1 - Policy learning - Constraints - Multiple outcome/PLUCR_package/PLUCR/")
devtools::load_all("./Documents/PhD/Project 1 - Policy learning - Constraints - Multiple outcome/PLUCR_package/PLUCR/")
rm(list=objects())
graphics.off()
`%>%`<- magrittr::`%>%`
library(PLUCR)
########################################
#  Preliminary step: Data preparation  #
########################################
## Parameters
n <- 2*1e3 # number of individuals
JFold <- 5 # Number of folds
Lambdas <- seq(0,8,by=1) # Lambda candidates
Betas <- c(0.05, 0.5, 1, 2) # Beta candidates
alpha <- 0.1 # constraint tolerance
precision <- 0.025 # Frank-Wolfe desired precision
centered <- FALSE
## Data generation
exp <- PLUCR::data_gen(n,seed=2025)
# Complete data
df_complete <- exp[[1]]
# Observational data
df_obs <- exp[[2]]
X <- df_obs %>%
dplyr::select(starts_with("X."))%>%
as.matrix()
Treatment <- df_obs$Treatment
Y <- df_obs$Y
Xi <- df_obs$Xi
# Folds for cross-validation
folds <- SuperLearner::CVFolds(N = n,id = NULL,Y = X,
cvControl = list(V = JFold, stratifyCV = FALSE, shuffle = TRUE))
folds_df <- do.call(rbind, lapply(seq_along(folds), function(v){data.frame(index=folds[[v]], fold=v)}))
s <- folds_df$fold[order(folds_df$index)]
########################################
# Step 1: Compute nuissance parameters #
########################################
initial_nparams <- PLUCR::nuissance_params(X, Treatment, Y, Xi,s)
# Primary outcome model
mu.hat.nj <- initial_nparams[[2]]
# Adverse event model
nu.hat.nj <- initial_nparams[[3]]
# Propensity score
ps.hat.nj <- initial_nparams[[4]]
fold <- 1
lambda <-0
beta <- 0.05
mu0 <- mu.hat.nj[[fold]]
nu0 <- nu.hat.nj[[fold]]
prop_score <- ps.hat.nj[[fold]]
out <- PLUCR::Optimization_Estimation(mu0, nu0, prop_score,
X, Treatment, Y, Xi,
lambda, alpha, precision, beta, centered,
paste0(lambda,"_",beta,"_",fold), paste0(lambda,"_",beta,"_",fold))
devtools::document("./Documents/PhD/Project 1 - Policy learning - Constraints - Multiple outcome/PLUCR_package/PLUCR/")
devtools::load_all("./Documents/PhD/Project 1 - Policy learning - Constraints - Multiple outcome/PLUCR_package/PLUCR/")
rm(list=objects())
graphics.off()
`%>%`<- magrittr::`%>%`
library(PLUCR)
########################################
#  Preliminary step: Data preparation  #
########################################
## Parameters
n <- 2*1e3 # number of individuals
JFold <- 5 # Number of folds
Lambdas <- seq(0,8,by=1) # Lambda candidates
Betas <- c(0.05, 0.5, 1, 2) # Beta candidates
alpha <- 0.1 # constraint tolerance
precision <- 0.025 # Frank-Wolfe desired precision
centered <- FALSE
## Data generation
exp <- PLUCR::data_gen(n,seed=2025)
# Complete data
df_complete <- exp[[1]]
# Observational data
df_obs <- exp[[2]]
X <- df_obs %>%
dplyr::select(starts_with("X."))%>%
as.matrix()
Treatment <- df_obs$Treatment
Y <- df_obs$Y
Xi <- df_obs$Xi
# Folds for cross-validation
folds <- SuperLearner::CVFolds(N = n,id = NULL,Y = X,
cvControl = list(V = JFold, stratifyCV = FALSE, shuffle = TRUE))
folds_df <- do.call(rbind, lapply(seq_along(folds), function(v){data.frame(index=folds[[v]], fold=v)}))
s <- folds_df$fold[order(folds_df$index)]
initial_nparams <- PLUCR::nuissance_params(X, Treatment, Y, Xi,s)
# Primary outcome model
mu.hat.nj <- initial_nparams[[2]]
# Adverse event model
nu.hat.nj <- initial_nparams[[3]]
# Propensity score
ps.hat.nj <- initial_nparams[[4]]
fold <- 1
beta <- 0.05
lambda <- 0
out <- PLUCR::Optimization_Estimation(mu0, nu0, prop_score,
X, Treatment, Y, Xi,
lambda, alpha, precision, beta, centered,
paste0(lambda,"_",beta,"_",fold), paste0(lambda,"_",beta,"_",fold))
mu0 <- mu.hat.nj[[fold]]
nu0 <- nu.hat.nj[[fold]]
prop_score <- ps.hat.nj[[fold]]
out <- PLUCR::Optimization_Estimation(mu0, nu0, prop_score,
X, Treatment, Y, Xi,
lambda, alpha, precision, beta, centered,
paste0(lambda,"_",beta,"_",fold), paste0(lambda,"_",beta,"_",fold))
out
devtools::document("./Documents/PhD/Project 1 - Policy learning - Constraints - Multiple outcome/PLUCR_package/PLUCR/")
devtools::load_all("./Documents/PhD/Project 1 - Policy learning - Constraints - Multiple outcome/PLUCR_package/PLUCR/")
fold <- 1
lambda <- 0
beta <- 0.05
`%>%`<- magrittr::`%>%`
library(PLUCR)
########################################
#  Preliminary step: Data preparation  #
########################################
## Parameters
n <- 2*1e3 # number of individuals
JFold <- 5 # Number of folds
Lambdas <- seq(0,8,by=1) # Lambda candidates
Betas <- c(0.05, 0.5, 1, 2) # Beta candidates
alpha <- 0.1 # constraint tolerance
precision <- 0.025 # Frank-Wolfe desired precision
centered <- FALSE
## Data generation
exp <- PLUCR::data_gen(n,seed=2025)
# Complete data
df_complete <- exp[[1]]
# Observational data
df_obs <- exp[[2]]
X <- df_obs %>%
dplyr::select(starts_with("X."))%>%
as.matrix()
Treatment <- df_obs$Treatment
Y <- df_obs$Y
Xi <- df_obs$Xi
# Folds for cross-validation
folds <- SuperLearner::CVFolds(N = n,id = NULL,Y = X,
cvControl = list(V = JFold, stratifyCV = FALSE, shuffle = TRUE))
folds_df <- do.call(rbind, lapply(seq_along(folds), function(v){data.frame(index=folds[[v]], fold=v)}))
s <- folds_df$fold[order(folds_df$index)]
initial_nparams <- PLUCR::nuissance_params(X, Treatment, Y, Xi,s)
# Primary outcome model
mu.hat.nj <- initial_nparams[[2]]
# Adverse event model
nu.hat.nj <- initial_nparams[[3]]
# Propensity score
ps.hat.nj <- initial_nparams[[4]]
mu0 <- mu.hat.nj[[fold]]
nu0 <- nu.hat.nj[[fold]]
prop_score <- ps.hat.nj[[fold]]
out <- PLUCR::Optimization_Estimation(mu0, nu0, prop_score,
X, Treatment, Y, Xi,
lambda, alpha, precision, beta, centered,
paste0(lambda,"_",beta,"_",fold), paste0(lambda,"_",beta,"_",fold))
offset_mu <- qlogis(mu0(Treatment,X))
offset_mu1 <- qlogis(mu0(1,X))
offset_mu0 <- qlogis(mu0(0,X))
offset_nu <- qlogis(nu0(Treatment,X))
offset_nu1 <- qlogis(nu0(1,X))
offset_nu0 <- qlogis(nu0(0,X))
devtools::document("./Documents/PhD/Project 1 - Policy learning - Constraints - Multiple outcome/PLUCR_package/PLUCR/")
devtools::load_all("./Documents/PhD/Project 1 - Policy learning - Constraints - Multiple outcome/PLUCR_package/PLUCR/")
rm(list=objects())
graphics.off()
`%>%`<- magrittr::`%>%`
library(PLUCR)
########################################
#  Preliminary step: Data preparation  #
########################################
## Parameters
n <- 2*1e3 # number of individuals
JFold <- 5 # Number of folds
Lambdas <- seq(1,8,by=1) # Lambda candidates
Betas <- c(0.05, 0.5, 1, 2) # Beta candidates
alpha <- 0.1 # constraint tolerance
precision <- 0.025 # Frank-Wolfe desired precision
centered <- FALSE
## Data generation
exp <- PLUCR::data_gen(n,seed=2025)
# Complete data
df_complete <- exp[[1]]
# Observational data
df_obs <- exp[[2]]
X <- df_obs %>%
dplyr::select(starts_with("X."))%>%
as.matrix()
Treatment <- df_obs$Treatment
Y <- df_obs$Y
Xi <- df_obs$Xi
# Folds for cross-validation
folds <- SuperLearner::CVFolds(N = n,id = NULL,Y = X,
cvControl = list(V = JFold, stratifyCV = FALSE, shuffle = TRUE))
folds_df <- do.call(rbind, lapply(seq_along(folds), function(v){data.frame(index=folds[[v]], fold=v)}))
s <- folds_df$fold[order(folds_df$index)]
initial_nparams <- PLUCR::nuissance_params(X, Treatment, Y, Xi,s)
# Primary outcome model
mu.hat.nj <- initial_nparams[[2]]
# Adverse event model
nu.hat.nj <- initial_nparams[[3]]
# Propensity score
ps.hat.nj <- initial_nparams[[4]]
fold <- 1
beta <- 0.05
lambda <- 0
mu0 <- mu.hat.nj[[fold]]
nu0 <- nu.hat.nj[[fold]]
prop_score <- ps.hat.nj[[fold]]
out <- PLUCR::Optimization_Estimation(mu0, nu0, prop_score,
X, Treatment, Y, Xi,
lambda, alpha, precision, beta, centered,
paste0(lambda,"_",beta,"_",fold), paste0(lambda,"_",beta,"_",fold))
devtools::document("./Documents/PhD/Project 1 - Policy learning - Constraints - Multiple outcome/PLUCR_package/PLUCR/")
devtools::load_all("./Documents/PhD/Project 1 - Policy learning - Constraints - Multiple outcome/PLUCR_package/PLUCR/")
rm(list=objects())
graphics.off()
`%>%`<- magrittr::`%>%`
library(PLUCR)
########################################
#  Preliminary step: Data preparation  #
########################################
## Parameters
n <- 2*1e3 # number of individuals
JFold <- 5 # Number of folds
Lambdas <- seq(1,8,by=1) # Lambda candidates
Betas <- c(0.05, 0.5, 1, 2) # Beta candidates
alpha <- 0.1 # constraint tolerance
precision <- 0.025 # Frank-Wolfe desired precision
centered <- FALSE
## Data generation
exp <- PLUCR::data_gen(n,seed=2025)
# Complete data
df_complete <- exp[[1]]
# Observational data
df_obs <- exp[[2]]
X <- df_obs %>%
dplyr::select(starts_with("X."))%>%
as.matrix()
Treatment <- df_obs$Treatment
Y <- df_obs$Y
Xi <- df_obs$Xi
# Folds for cross-validation
folds <- SuperLearner::CVFolds(N = n,id = NULL,Y = X,
cvControl = list(V = JFold, stratifyCV = FALSE, shuffle = TRUE))
folds_df <- do.call(rbind, lapply(seq_along(folds), function(v){data.frame(index=folds[[v]], fold=v)}))
s <- folds_df$fold[order(folds_df$index)]
########################################
# Step 1: Compute nuissance parameters #
########################################
initial_nparams <- PLUCR::nuissance_params(X, Treatment, Y, Xi,s)
# Primary outcome model
mu.hat.nj <- initial_nparams[[2]]
# Adverse event model
nu.hat.nj <- initial_nparams[[3]]
# Propensity score
ps.hat.nj <- initial_nparams[[4]]
fold <- 1
beta <- 0.05
lambda <- 0
mu0 <- mu.hat.nj[[fold]]
nu0 <- nu.hat.nj[[fold]]
prop_score <- ps.hat.nj[[fold]]
out <- PLUCR::Optimization_Estimation(mu0, nu0, prop_score,
X, Treatment, Y, Xi,
lambda, alpha, precision, beta, centered,
paste0(lambda,"_",beta,"_",fold), paste0(lambda,"_",beta,"_",fold))
ls
out
names(out)
theta_collection <- out$theta_collection
theta_collection
`%>%`<- magrittr::`%>%`
library(PLUCR)
########################################
#  Preliminary step: Data preparation  #
########################################
## Parameters
n <- 2*1e3 # number of individuals
JFold <- 5 # Number of folds
Lambdas <- seq(1,8,by=1) # Lambda candidates
Betas <- c(0.05, 0.5, 1, 2) # Beta candidates
alpha <- 0.1 # constraint tolerance
precision <- 0.025 # Frank-Wolfe desired precision
centered <- FALSE
## Data generation
exp <- PLUCR::data_gen(n,seed=2025)
# Complete data
df_complete <- exp[[1]]
# Observational data
df_obs <- exp[[2]]
X <- df_obs %>%
dplyr::select(starts_with("X."))%>%
as.matrix()
Treatment <- df_obs$Treatment
Y <- df_obs$Y
Xi <- df_obs$Xi
# Folds for cross-validation
folds <- SuperLearner::CVFolds(N = n,id = NULL,Y = X,
cvControl = list(V = JFold, stratifyCV = FALSE, shuffle = TRUE))
folds_df <- do.call(rbind, lapply(seq_along(folds), function(v){data.frame(index=folds[[v]], fold=v)}))
s <- folds_df$fold[order(folds_df$index)]
########################################
# Step 1: Compute nuissance parameters #
########################################
initial_nparams <- PLUCR::nuissance_params(X, Treatment, Y, Xi,s)
library(PLUCR)
devtools::document("./Documents/PhD/Project 1 - Policy learning - Constraints - Multiple outcome/PLUCR_package/PLUCR/")
devtools::load_all("./Documents/PhD/Project 1 - Policy learning - Constraints - Multiple outcome/PLUCR_package/PLUCR/")
devtools::install("./Documents/PhD/Project 1 - Policy learning - Constraints - Multiple outcome/PLUCR_package/PLUCR/")
library(PLUCR)
nuissance_params()
devtools::install("./Documents/PhD/Project 1 - Policy learning - Constraints - Multiple outcome/PLUCR_package/PLUCR/")
remove.packages("PLUCR")
install.packages("PLUCR")
devtools::document()
getwd()
setwd("~/Documents/PhD/Project 1 - Policy learning - Constraints - Multiple outcome/PLUCR_package/PLUCR/R")
devtools::document()
devtools::build()
devtools::install()
`%>%`<- magrittr::`%>%`
library(PLUCR)
########################################
#  Preliminary step: Data preparation  #
########################################
## Parameters
n <- 2*1e2 # number of individuals
JFold <- 5 # Number of folds
Lambdas <- seq(1,8,by=1) # Lambda candidates
Betas <- c(0.05, 0.5, 1, 2) # Beta candidates
alpha <- 0.1 # constraint tolerance
precision <- 0.025 # Frank-Wolfe desired precision
centered <- FALSE
SL.library <- c(
"SL.mean",        # Simple baseline
"SL.glm",         # Generalized Linear Model (logistic regression)
"SL.ranger"      # Fast implementation of Random Forest
)
## Data generation
exp <- PLUCR::data_gen(n,seed=2025)
# Complete data
df_complete <- exp[[1]]
# Observational data
df_obs <- exp[[2]]
X <- df_obs %>%
dplyr::select(starts_with("X."))%>%
as.matrix()
A <- df_obs$Treatment
Y <- df_obs$Y
Xi <- df_obs$Xi
# Folds for cross-validation
folds <- SuperLearner::CVFolds(N = n,id = NULL,Y = X,
cvControl = list(V = JFold, stratifyCV = FALSE, shuffle = TRUE))
folds_df <- do.call(rbind, lapply(seq_along(folds), function(v){data.frame(index=folds[[v]], fold=v)}))
s <- folds_df$fold[order(folds_df$index)]
checks<- PLUCR::check_data(Y,Xi,A,X,s)
########################################
# Step 1: Compute nuisance parameters #
########################################
# Primary outcome model
mu.hat.nj <- PLUCR::estimate_mu(Y=Y, A=A, X=X,folds=s, V = 3, SL.library = SL.library)
########################################
# Step 1: Compute nuisance parameters #
########################################
# Primary outcome model
mu.hat.nj <- PLUCR::estimate_mu(Y=Y, A=A, X=as.data.frame(X),folds=s, V = 3, SL.library = SL.library)
library(SuperLearner)
########################################
# Step 1: Compute nuisance parameters #
########################################
# Primary outcome model
mu.hat.nj <- PLUCR::estimate_mu(Y=Y, A=A, X=as.data.frame(X),folds=s, V = 3, SL.library = SL.library)
devtools::document()
devtools::build()
devtools::install()
source("~/Documents/PhD/Project 1 - Policy learning - Constraints - Multiple outcome/PLUCR_package/algorithm.R")
traceback()
?CVFolds
# Folds for cross-validation
folds <- SuperLearner::CVFolds(n, cvControl = list(V = JFold, shuffle = TRUE))
# Folds for cross-validation
folds <- SuperLearner::CVFolds(n, cvControl = list(V = JFold, shuffle = TRUE))
traceback()
# Folds for cross-validation
folds <- SuperLearner::CVFolds(n, cvControl = SuperLearner.CV.control(V = JFold, shuffle = TRUE))
?SuperLearner.CV.control
# Folds for cross-validation
folds <- SuperLearner::CVFolds(n, cvControl = SuperLearner::SuperLearner.CV.control(V = JFold, shuffle = TRUE))
SuperLearner::SuperLearner.CV.control(V = JFold, shuffle = TRUE
)
?CVFolds
# Folds for cross-validation
folds <- SuperLearner::CVFolds(n,
id = NULL,
Y = Y,
cvControl = SuperLearner::SuperLearner.CV.control(V = JFold, shuffle = TRUE))
folds_df <- do.call(rbind, lapply(seq_along(folds), function(v){data.frame(index=folds[[v]], fold=v)}))
s <- folds_df$fold[order(folds_df$index)]
checks<- PLUCR::check_data(Y,Xi,A,X,s)
########################################
# Step 1: Compute nuisance parameters #
########################################
# Primary outcome model
mu.hat.nj <- PLUCR::estimate_mu(Y=Y, A=A, X=X,folds=s, V = 3, SL.library = SL.library)
traceback()
JFold <- 5L # Number of folds
# Folds for cross-validation
folds <- SuperLearner::CVFolds(n,
id = NULL,
Y = Y,
cvControl = SuperLearner::SuperLearner.CV.control(V = JFold, shuffle = TRUE))
folds_df <- do.call(rbind, lapply(seq_along(folds), function(v){data.frame(index=folds[[v]], fold=v)}))
s <- folds_df$fold[order(folds_df$index)]
checks<- PLUCR::check_data(Y,Xi,A,X,s)
########################################
# Step 1: Compute nuisance parameters #
########################################
# Primary outcome model
mu.hat.nj <- PLUCR::estimate_mu(Y=Y, A=A, X=X,folds=s, V = 3, SL.library = SL.library)
debug(estimate_mu)
########################################
# Step 1: Compute nuisance parameters #
########################################
# Primary outcome model
mu.hat.nj <- PLUCR::estimate_mu(Y=Y, A=A, X=X,folds=s, V = 3, SL.library = SL.library)
########################################
# Step 1: Compute nuisance parameters #
########################################
# Primary outcome model
mu.hat.nj <- PLUCR::estimate_mu(Y=Y, A=A, X=X,folds=s, V = 3, SL.library = SL.library)
fold
folds
source("~/Documents/PhD/Project 1 - Policy learning - Constraints - Multiple outcome/PLUCR_package/algorithm.R")
source("~/Documents/PhD/Project 1 - Policy learning - Constraints - Multiple outcome/PLUCR_package/algorithm.R")
undebug(estimate_mu)
source("~/Documents/PhD/Project 1 - Policy learning - Constraints - Multiple outcome/PLUCR_package/algorithm.R")
mu.hat.nj
ttt <- mu.hat.nj(1, X, 1)
ttt <- mu.hat.nj(rep(1, nrow(X)), X, 1)
uuu <- mu.hat.nj(rep(0, nrow(X)), X, 1)
quantile(ttt)
quantile(uuu)
ls(environment(mu.hat.nj))
get("objects0", environment(mu.hat.nj))
