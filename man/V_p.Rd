% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/utils.R
\name{V_p}
\alias{V_p}
\title{Oracular Approximation of Value Function}
\usage{
V_p(psi, beta = 0.05, centered = FALSE, alpha = 0.05, B = 10000, seed = NA)
}
\arguments{
\item{psi}{A function that takes a numeric matrix \code{X} as input and returns a numeric vector.}

\item{beta}{A numeric scalar (0.05 by default) controlling the sharpness of the probability function.}

\item{centered}{A logical (FALSE by default) indicating whether to apply centering in \code{sigma_beta}.}

\item{alpha}{A numeric scalar (0.05 by default) representing the constraint tolerance (not directly used here but for consistency).}

\item{B}{Integer (default 1e4) number of Monte Carlo repetitions.}

\item{seed}{Integer or NA (default value).}

\item{X}{A numeric matrix of size n x d (input data).}

\item{counterfactual_outcomes}{A list of length 2 containing:
\itemize{
\item \code{counterfactual_outcomes[[1]]}: Outcome if treated (\eqn{Y(1)}).
\item \code{counterfactual_outcomes[[2]]}: Outcome if not treated (\eqn{Y(0)}).
}}
}
\value{
A numeric scalar representing the expected outcome under the policy.
}
\description{
Computes the expected outcome under a policy determined by the previously optimized \code{psi(X)}.
The policy assigns treatment probabilistically based on \code{sigma_beta(psi(X))},
and the expected outcome is calculated using counterfactual outcomes.
}
